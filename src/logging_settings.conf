# RedLLM Enhanced Logging Configuration
# 
# This file allows you to customize logging behavior without modifying code.
# Uncomment and modify the settings below as needed.

[logging]
# Verbose level: 0=errors only, 1=normal, 2=debug, 3=verbose debug
verbose_level = 1

# Console output settings
show_colors = true
show_icons = true
max_message_length = 200

# LiteLLM filtering settings
filter_litellm_debug = true
filter_long_messages = true

# Critical error handling
pause_on_critical_errors = true
auto_skip_failed_judges = false

# File logging
log_file = "redllm.log"
rotate_logs = true
max_log_size_mb = 10

# Specific logger levels (uncomment to override)
# [logger_levels]
# litellm = WARNING
# httpx = ERROR
# openai = WARNING
# anthropic = WARNING
# urllib3 = ERROR
# requests = ERROR

# Patterns to always show (even in debug filtering)
[important_patterns]
patterns = [
    "authentication",
    "api key", 
    "rate limit",
    "quota",
    "billing",
    "error",
    "failed",
    "exception",
    "timeout",
    "critical"
]

# Patterns to always filter out
[noise_patterns]  
patterns = [
    "model_info:",
    "Final returned optional params:",
    "self.optional_params:",
    "Only some together models support",
    "Docs - https://docs.together.ai",
    "chat.py:",
    "utils.py:",
    "litellm_logging.py:"
]
